{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pypi.org/project/spacy-lefff/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy-lefff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-04 00:36:31,041 - spacy_lefff.lefff - INFO - New LefffLemmatizer instantiated.\n",
      "2021-02-04 00:36:31,043 - spacy_lefff.lefff - INFO - Token lefff_lemma already registered\n",
      "2021-02-04 00:36:31,044 - spacy_lefff.lefff - INFO - Reading lefff data...\n",
      "2021-02-04 00:36:32,171 - spacy_lefff.lefff - INFO - Successfully loaded lefff lemmatizer\n",
      "Apple NOUN None NOUN__Gender=Masc|Number=Sing apple\n",
      "cherche NOUN cherche NOUN__Gender=Fem|Number=Sing cherche\n",
      "a AUX None AUX__Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin avoir\n",
      "acheter VERB acheter VERB__VerbForm=Inf acheter\n",
      "une DET un DET__Definite=Ind|Gender=Fem|Number=Sing|PronType=Art un\n",
      "startup ADJ None ADJ__Number=Sing startup\n",
      "anglaise NOUN anglaise NOUN__Gender=Fem|Number=Sing anglaise\n",
      "pour ADP None ADP pour\n",
      "1 NUM None NUM__NumType=Card 1\n",
      "milliard NOUN milliard NOUN__Gender=Masc|Number=Sing|NumType=Card milliard\n",
      "de ADP un ADP de\n",
      "dollard PROPN None PROPN__Gender=Masc|Number=Sing dollard\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy_lefff import LefffLemmatizer, POSTagger\n",
    "\n",
    "nlp = spacy.load('fr')\n",
    "french_lemmatizer = LefffLemmatizer()\n",
    "nlp.add_pipe(french_lemmatizer, name='lefff')\n",
    "doc = nlp(u\"Apple cherche a acheter une startup anglaise pour 1 milliard de dollard\")\n",
    "for d in doc:\n",
    "    print(d.text, d.pos_, d._.lefff_lemma, d.tag_, d.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, List, Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrenchLemmatizer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('fr')\n",
    "        self.lemmatizer = LefffLemmatizer()\n",
    "        self.nlp.add_pipe(self.lemmatizer, name='lefff')\n",
    "        \n",
    "    def lemmatize(self, sentence: Iterable[Text]) -> List[Text]:\n",
    "        doc = self.nlp(\" \".join(sentence))\n",
    "        return [d.lemma_ for d in doc]\n",
    "\n",
    "    def lemmatize_s(self, sentence: Text) -> List[Text]:\n",
    "        doc = self.nlp(sentence)\n",
    "        return [d.lemma_ for d in doc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-04 00:47:01,598 - spacy_lefff.lefff - INFO - New LefffLemmatizer instantiated.\n",
      "2021-02-04 00:47:01,599 - spacy_lefff.lefff - INFO - Token lefff_lemma already registered\n",
      "2021-02-04 00:47:01,600 - spacy_lefff.lefff - INFO - Reading lefff data...\n",
      "2021-02-04 00:47:02,372 - spacy_lefff.lefff - INFO - Successfully loaded lefff lemmatizer\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = FrenchLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple',\n",
       " 'cherche',\n",
       " 'avoir',\n",
       " 'acheter',\n",
       " 'un',\n",
       " 'startup',\n",
       " 'anglaise',\n",
       " 'pour',\n",
       " '1',\n",
       " 'milliard',\n",
       " 'de',\n",
       " 'dollard']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%timeit\n",
    "lemmatizer.lemmatize_s(\"Apple cherche a acheter une startup anglaise pour 1 milliard de dollard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['honoré',\n",
       " 'de',\n",
       " 'balzac',\n",
       " 'code',\n",
       " 'de',\n",
       " 'gens',\n",
       " 'honnête',\n",
       " 'ou',\n",
       " 'l',\n",
       " 'art',\n",
       " 'de',\n",
       " 'ne',\n",
       " 'pas',\n",
       " 'être',\n",
       " 'dupe',\n",
       " 'de',\n",
       " 'fripon',\n",
       " '1825',\n",
       " 'avant',\n",
       " 'propos',\n",
       " 'l',\n",
       " 'argent',\n",
       " 'par',\n",
       " 'le',\n",
       " 'temps',\n",
       " 'qui',\n",
       " 'court',\n",
       " 'donne',\n",
       " 'le',\n",
       " 'plaisir',\n",
       " 'le',\n",
       " 'considération',\n",
       " 'le',\n",
       " 'ami',\n",
       " 'le',\n",
       " 'succès',\n",
       " 'le',\n",
       " 'talent',\n",
       " 'l',\n",
       " 'esprit',\n",
       " 'même',\n",
       " 'ce',\n",
       " 'dou',\n",
       " 'métal',\n",
       " 'devoir',\n",
       " 'donc',\n",
       " 'être',\n",
       " 'l',\n",
       " 'objet',\n",
       " 'conster',\n",
       " 'de',\n",
       " 'l',\n",
       " 'amour',\n",
       " 'et',\n",
       " 'de',\n",
       " 'le',\n",
       " 'sollicitude',\n",
       " 'de',\n",
       " 'mortel',\n",
       " 'de',\n",
       " 'tout',\n",
       " 'âge',\n",
       " 'de',\n",
       " 'tout',\n",
       " 'condition',\n",
       " 'depuis',\n",
       " 'le',\n",
       " 'roi',\n",
       " 'jusqu',\n",
       " 'à',\n",
       " 'grisette',\n",
       " 'depuis',\n",
       " 'le',\n",
       " 'propriétaire',\n",
       " 'jusqu',\n",
       " 'à',\n",
       " 'émigré']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize_s(\"honoré de balzac code des gens honnêtes ou l art de ne pas être dupe des fripons 1825 avant propos l argent par le temps qui court donne le plaisir la considération les amis les succès les talents l esprit même ce doux métal doit donc être l objet constant de l amour et de la sollicitude des mortels de tout âge de toute condition depuis les rois jusqu aux grisettes depuis les propriétaires jusqu aux émigrés\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paier']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize_s(\"paier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
